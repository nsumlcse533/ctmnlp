{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "smsnlprajib_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyOo9cTlcIPA",
        "colab_type": "text"
      },
      "source": [
        "# Step 1: Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlWMVj9rkWk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#a = []\n",
        "#while(1):\n",
        "#a.append(‘1’)\n",
        "#import tensorflow.compat.v1 as tf\n",
        "#tf.disable_v2_behavior()\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycnUDX2wuKQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip uninstall tensorflow\n",
        "#!pip uninstall tensorflow-gpu\n",
        "#!pip install tensorflow==1.5\n",
        "#!pip install tensorflow-gpu==1.5\n",
        "#!pip install tensorflow-gpu==2.0.0-alpha0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDsBTfw6cIPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Required Library and sysnc with gib\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import nltk\n",
        "#nltk.download('stopwords')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import feature_extraction, model_selection, naive_bayes, metrics, svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Try for RNN based on LSTM as per suggestion of SIR\n",
        "from keras.models import Model\n",
        "from keras.layers import SimpleRNN, LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "#import tensorflow.compat.v1 as tf\n",
        "#tf.disable_v2_behavior()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09YUAiqVcIPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the dataset of SMS messages\n",
        "#url = 'https://github.com/nsumlcse533/ctmnlp/blob/master/1935376/SMSSpamCollection'\n",
        "#df1 = pd.read_table(url)\n",
        "#df = pd.read_table(url, header=None, encoding='utf-8')\n",
        "#df = pd.read_table(io.StringIO(uploaded['SMSSPamCollection'].decode('utf-8')))\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jcujgi6McIQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "df = pd.read_table(io.BytesIO(uploaded['SMSSpamCollection']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZZb4fWDcIQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print useful information about the dataset\n",
        "print(df.info())\n",
        "print(df.head(5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M286wJvocIQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDNvGbjtcIQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR39tOFrcIQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Rename of Columns from 0,1 to type,sms for better understanding\n",
        "df.columns = ['type','sms']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8Uu2BcBcIQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Check if the column rename completed\n",
        "df.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrHxJiWkcIQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check the header data after column rename\n",
        "df.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9KNhk5TcIQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check the data type wise status\n",
        "df.groupby('type').describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLVyYJdUcIQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check the character length for each message to analyze typical lengh of ham or spam messages\n",
        "df['length'] = df['sms'].map(lambda text: len(text))\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2diirSKcIQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot the sms length in histogram for analyze the length nature\n",
        "df.length.plot(bins=20, kind='hist')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_NwqjpecIQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Find the mean value for length\n",
        "df.length.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIq6w5EOcIQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#What is the long message?\n",
        "print(df.sms[df.length > 900])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjzk3roZcIQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Difference in message length between spam and ham.\n",
        "df.hist(column='length', by='type', bins=70)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtNaevaTcIQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compare the types of HAM (non SPAM) vs SPAM\n",
        "sns.countplot(data = df, x= df[\"type\"]).set_title(\"Amount of spam and no-spam messages\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5-5Z-xIcIQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# count number of records\n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8zmIwolcIQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[df==np.inf]=np.nan\n",
        "df.fillna(df.mean(), inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mOMyp6tcIQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check and remove duplicate\n",
        "df.drop_duplicates(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2kXUw-lcIQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check after duplicate remove \n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmSXrLj_cIQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compare the types of HAM (non SPAM) vs SPAM after duplicate removal\n",
        "sns.countplot(data = df, x= df[\"type\"]).set_title(\"Amount of non duplicate spam and no-spam messages\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_egq3ZGcISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find for missing data\n",
        "df.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouFBDsMqcISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[\"type\"].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axseTO9GcISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Text Analytics find the frequencies of words in the spam and non-spam messages\n",
        "count1 = Counter(\" \".join(df[df['type']=='ham'][\"sms\"]).split()).most_common(20)\n",
        "df1 = pd.DataFrame.from_dict(count1)\n",
        "df1 = df1.rename(columns={0: \"words in non-spam\", 1 : \"count\"})\n",
        "count2 = Counter(\" \".join(df[df['type']=='spam'][\"sms\"]).split()).most_common(20)\n",
        "df2 = pd.DataFrame.from_dict(count2)\n",
        "df2 = df2.rename(columns={0: \"words in spam\", 1 : \"count_\"})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFL7nVDScISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItST5C0ScISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Most used words\n",
        "df1.plot.bar(legend = False)\n",
        "y_pos = np.arange(len(df1[\"words in non-spam\"]))\n",
        "plt.xticks(y_pos, df1[\"words in non-spam\"])\n",
        "plt.title('Most used words in non-spam messages')\n",
        "plt.xlabel('words')\n",
        "plt.ylabel('number')\n",
        "plt.show()\n",
        "df2.plot.bar(legend = False, color = 'orange')\n",
        "y_pos = np.arange(len(df2[\"words in spam\"]))\n",
        "plt.xticks(y_pos, df2[\"words in spam\"])\n",
        "plt.title('Most used words in spam messages')\n",
        "plt.xlabel('words')\n",
        "plt.ylabel('number')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6WRvG4GcISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# From above we find the majority of frequent words in both classes are stop words such as 'to', 'a', 'or' etc...."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfFw5nnFcISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#converting categorical data in numeric labels || split a message into its individual words\n",
        "# 0=ham,1=spam\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder=LabelEncoder()\n",
        "classes=df[\"type\"]\n",
        "Y=encoder.fit_transform(classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdnmHKevcISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_messages=df[\"sms\"]\n",
        "text_messages.sample(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTnaipm7cISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove regular expressions and stop words\n",
        "# using regular expressions to replace email addresses, URLs, phone numbers, other numbers\n",
        "\n",
        "# Replacing email addresses with 'email'\n",
        "processed = text_messages.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$',\n",
        "                                 'emailaddress')\n",
        "\n",
        "# Replacing URLs with 'webaddress'\n",
        "processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n",
        "                                  'webaddress')\n",
        "\n",
        "# Replacing money symbols with 'moneysymb' (£ can by typed with ALT key + 156)\n",
        "processed = processed.str.replace(r'£|\\$', 'moneysymbol')\n",
        "    \n",
        "# Replacing 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n",
        "processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\n",
        "                                  'phonenumber')\n",
        "    \n",
        "# Replacing numbers with 'number'\n",
        "processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'number')\n",
        "\n",
        "# Removing punctuation\n",
        "processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
        "\n",
        "# Replacing whitespace between terms with a single space\n",
        "processed = processed.str.replace(r'\\s+', ' ')\n",
        "\n",
        "# Removing leading and trailing whitespace\n",
        "processed = processed.str.replace(r'^\\s+|\\s+?$', '')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxBaKgimcISI",
        "colab_type": "text"
      },
      "source": [
        "# Step 2: Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2OaGChKcISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the raw sms (sequence of characters) into vectors (sequences of numbers)."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS4T4DDTcISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove the stop words in order to improve the analytics\n",
        "f = feature_extraction.text.CountVectorizer(stop_words = 'english')\n",
        "X = f.fit_transform(df[\"sms\"]) #data set\n",
        "np.shape(X)\n",
        "#created more than 8400 new features. The new feature  j  in the row  i  is equal to 1 if the word  wj  appears in the text example  i . It is zero if not."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9SnpqC_cISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here we transform the variable spam/non-spam into binary variable, \n",
        "Y=df[\"type\"].map({'spam':1,'ham':0}) #target\n",
        "#df[\"type\"]=df[\"type\"].map({'spam':1,'ham':0})\n",
        "#df[\"type\"].head(5)\n",
        "\n",
        "# then split target data set in training set (train test split function) and test set.we want 33% of data into the test set, \n",
        "# use randon_state=42 of same set of data every time and cosistent result\n",
        "\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size=0.33, random_state=42)\n",
        "print([np.shape(X_train), np.shape(X_test)])\n",
        "print([np.shape(y_train), np.shape(y_test)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNcF1ZPPcISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Multinomial naive bayes classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNpR6eu-cISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MultiNB = MultinomialNB()\n",
        "MultiNB.fit(X_train, y_train)\n",
        "print(MultiNB)\n",
        "y_pred=MultiNB.predict(X_test)\n",
        "print (accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx343SflcISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Bernoulli \n",
        "BernNB = BernoulliNB(binarize=True)\n",
        "BernNB.fit(X_train, y_train)\n",
        "print(BernNB)\n",
        "y_pred=BernNB.predict(X_test)\n",
        "print (accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eao-KN92cISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we found that the accuracy score of Multinomial is very high, So bellow we will try to analyze bayes based on Multinomial"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ygsMaxRcISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "array_alpha = np.arange(1/100000, 20, 0.11) #array creation routines based on numerical rangesnumpy.arange([start, ]stop, [step, ], dtype=None)\n",
        "# create some score set for test the result\n",
        "score_train = np.zeros(len(array_alpha)) \n",
        "score_test = np.zeros(len(array_alpha))\n",
        "recall_test = np.zeros(len(array_alpha))\n",
        "precision_test= np.zeros(len(array_alpha))\n",
        "count = 0\n",
        "for alpha in array_alpha:\n",
        "    bayes = naive_bayes.MultinomialNB(alpha=alpha)\n",
        "    bayes.fit(X_train, y_train)\n",
        "    score_train[count] = bayes.score(X_train, y_train)\n",
        "    score_test[count]= bayes.score(X_test, y_test)\n",
        "    recall_test[count] = metrics.recall_score(y_test, bayes.predict(X_test))\n",
        "    precision_test[count] = metrics.precision_score(y_test, bayes.predict(X_test))\n",
        "    count = count + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saF0jk7hcISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create matrix for test and pring different models\n",
        "matrix = np.matrix(np.c_[array_alpha, score_train, score_test, recall_test, precision_test])\n",
        "models = pd.DataFrame(data = matrix, columns = ['alpha', 'Train Accuracy', 'Test Accuracy', 'Test Recall', 'Test Precision'])\n",
        "models.head(n=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epVoyrsHcISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#find the model with the most test precision and details relation with other model\n",
        "best_index = models['Test Precision'].idxmax()\n",
        "models.iloc[best_index, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kcndx8ecISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# So the selected best model does not produce any false positive, which is our goal.\n",
        "#Now find if there is more than one model with 100% precision !\n",
        "models[models['Test Precision']==1].head(n=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAJdzgTVcISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Between these models with the highest possible precision, we are going to select which has more test accuracy.\n",
        "best_index = models[models['Test Precision']==1]['Test Accuracy'].idxmax()\n",
        "bayes = naive_bayes.MultinomialNB(alpha = array_alpha[best_index])\n",
        "bayes.fit(X_train, y_train)\n",
        "models.iloc[best_index, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbpklMpxcISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Confusion matrix with naive bayes classifier\n",
        "m_confusion_test = metrics.confusion_matrix(y_test, bayes.predict(X_test))\n",
        "pd.DataFrame(data = m_confusion_test, columns = ['Predicted 0', 'Predicted 1'],\n",
        "            index = ['Actual 0', 'Actual 1'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qflAvqGmcISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Out of the 1485 actual instances of 'ham' (not spam), it predicted correctly all of them;\n",
        "# Out of the 172 actual instances of spam, it predicted correctly 136 of them.\n",
        "# The accuracy obtained from the confusion matrix, as the sum of the diagonal divided by the sum of all matrix entries:\n",
        "(m_confusion_test[0,0]+m_confusion_test[1,1])/np.sum(m_confusion_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxymqAIccISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfJgGvBUcISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Support Venctor Machine Test, we will evaluate the accuracy, recall and precision of the model with the test set.\n",
        "# We train different models changing the regularization parameter C."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXK45vcacISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import warnings filter due to getting warning as \"The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\"\n",
        "from warnings import simplefilter\n",
        "# ignore all future warnings\n",
        "simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "list_C = np.arange(500, 2000, 100) #100000\n",
        "score_train = np.zeros(len(list_C))\n",
        "score_test = np.zeros(len(list_C))\n",
        "recall_test = np.zeros(len(list_C))\n",
        "precision_test= np.zeros(len(list_C))\n",
        "count = 0\n",
        "for C in list_C:\n",
        "    svc = svm.SVC(C=C)\n",
        "    svc.fit(X_train, y_train)\n",
        "    score_train[count] = svc.score(X_train, y_train)\n",
        "    score_test[count]= svc.score(X_test, y_test)\n",
        "    recall_test[count] = metrics.recall_score(y_test, svc.predict(X_test))\n",
        "    precision_test[count] = metrics.precision_score(y_test, svc.predict(X_test))\n",
        "    count = count + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4PAFEW0cISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create matrix for test and pring different models\n",
        "matrix = np.matrix(np.c_[list_C, score_train, score_test, recall_test, precision_test])\n",
        "models = pd.DataFrame(data = matrix, columns = \n",
        "             ['C', 'Train Accuracy', 'Test Accuracy', 'Test Recall', 'Test Precision'])\n",
        "models.head(n=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5nXR0DlcISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# select the model with the most test precision\n",
        "best_index = models['Test Precision'].idxmax()\n",
        "models.iloc[best_index, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhT_bFUucITs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# here also our best model does not produce any false positive, which is our goal.\n",
        "# we will find if there is more than one model with 100% precision !\n",
        "models[models['Test Precision']>0.99].head(n=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiYCi-NAcITs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compare these models with the highest possible precision.\n",
        "best_index = models[models['Test Precision']>0.99]['Test Accuracy'].idxmax()\n",
        "svc = svm.SVC(C=list_C[best_index])\n",
        "svc.fit(X_train, y_train)\n",
        "models.iloc[best_index, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12XRhQ4FcITs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Confusion matrix with support vector machine classifier.\n",
        "svm_confusion_test = metrics.confusion_matrix(y_test, svc.predict(X_test))\n",
        "pd.DataFrame(data = svm_confusion_test, columns = ['Predicted 0', 'Predicted 1'],\n",
        "            index = ['Actual 0', 'Actual 1'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMgpAB6jcITs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Out of the 1482 actual instances of 'ham' (not spam), it predicted correctly all of them;\n",
        "# Out of the 189 actual instances of spam, it predicted correctly 154 of them.\n",
        "# The accuracy obtained from the confusion matrix, as the sum of the diagonal divided by the sum of all matrix entries:\n",
        "(svm_confusion_test[0,0]+svm_confusion_test[1,1])/np.sum(svm_confusion_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wJsY_MNcITs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# After comparing the NB and SVM, we found that support vector machine with more than 98% accuracy(NB=0.9742086752637749 || SVM = 0.9894841735052755)."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQOkpAKscITs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we will now LSTM ''' Tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZXOCCcacITs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnJniX3qxmDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import tensorflow.compat.v1 as tf\n",
        "#tf.disable_v2_behavior()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzJaEzAvcITs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_words = 1000\n",
        "max_len = 150\n",
        "#tok = Tokenizer(num_words=max_words)\n",
        "\n",
        "#tok.fit_on_texts(X_train)\n",
        "#sequences = tok.texts_to_sequences(X_train)\n",
        "#sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMJ80rK1cITs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_words, 32))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history_ltsm = model.fit(X_train, y_train, epochs=5, batch_size=60, validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhqieqnicITs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#def RNN():\n",
        "#    inputs = Input(name='inputs',shape=[max_len])\n",
        "#    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
        "#    layer = LSTM(64)(layer)\n",
        "#    layer = Dense(256,name='FC1')(layer)\n",
        "#    layer = Activation('relu')(layer)\n",
        "#    layer = Dropout(0.5)(layer)\n",
        "#    layer = Dense(1,name='out_layer')(layer)\n",
        "#    layer = Activation('sigmoid')(layer)\n",
        "#    model = Model(inputs=inputs,outputs=layer)\n",
        "#    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QM3JOlvcITs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model = RNN()\n",
        "#model.summary()\n",
        "#model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0gVkwgycITs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history_ltsm.history['acc']\n",
        "val_acc = history_ltsm.history['val_acc']\n",
        "loss = history_ltsm.history['loss']\n",
        "val_loss = history_ltsm.history['val_loss']\n",
        "epochs = range(len(acc))\n",
        "plt.plot(epochs, acc, '-', color='orange', label='training acc')\n",
        "plt.plot(epochs, val_acc, '-', color='blue', label='validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochs, loss, '-', color='orange', label='training acc')\n",
        "plt.plot(epochs, val_loss,  '-', color='blue', label='validation acc')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAT_kP9VcITs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict_classes(X_test)\n",
        "acc = model.evaluate(X_test, y_test)\n",
        "proba_ltsm = model.predict_proba(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(\"Test loss is {0:.2f} accuracy is {1:.2f}  \".format(acc[0],acc[1]))\n",
        "print(confusion_matrix(pred, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MLVGhKCIGMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# After comparing the NB and SVM, we found that \n",
        "# support vector machine with more than 98% accuracy\n",
        "# NB= 97%| SVM = 98% || LSTM = 87% \n",
        "# summery is LSTM may give more accurate result, but for our run we have tried for epochs=5, i think epochs=30 should give above 98% accuracy."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0c6UdzmIM4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############# END OF THE PROJECT CODE ############################"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}